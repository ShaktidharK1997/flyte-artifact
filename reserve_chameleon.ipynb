{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reserve and configure resources on KVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you run this experiment, you will:\n",
    "\n",
    "-   define the specific configuration of resources you need.\n",
    "-   “instantiate” an experiment with your reserved resources.\n",
    "-   wait for your resources to be configured.\n",
    "-   log in to resources to carry out the experiment.\n",
    "\n",
    "This exercise will guide you through those steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openstack, chi, chi.ssh, chi.network, chi.server, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we configure the Chameleon Python client.\n",
    "\n",
    "For this experiment, we’re going to use the KVM@TACC site, which we indicate below.\n",
    "\n",
    "We also need to specify the name of the Chameleon “project” that this experiment is part of. The project name will have the format “CHI-XXXXXX”, where the last part is a 6-digit number, and you can find it on your [user dashboard](https://chameleoncloud.org/user/dashboard/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, replace the project ID with your own project ID, then run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now using KVM@TACC:\n",
      "URL: https://kvm.tacc.chameleoncloud.org\n",
      "Location: Austin, Texas, USA\n",
      "Support contact: help@chameleoncloud.org\n"
     ]
    }
   ],
   "source": [
    "chi.use_site(\"KVM@TACC\")\n",
    "PROJECT_NAME = \"CHI-231138\"\n",
    "chi.set(\"project_name\", PROJECT_NAME)\n",
    "\n",
    "# configure openstacksdk for actions unsupported by python-chi\n",
    "os_conn = chi.clients.connection()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define configuration for this experiment (3 VMs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this specific experiment, we will need three virtual machines connected to a common network. Each of the virtual machines will be of the `m1.large` type, with 4 VCPUs, 8 GB memory, 40 GB disk space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "username = os.getenv('USER')\n",
    "\n",
    "node_conf = [\n",
    " {'name': \"node-0\",  'flavor': 'm1.medium', 'image': 'CC-Ubuntu20.04', 'packages': [\"virtualenv\"], 'bastion': True}, \n",
    " {'name': \"node-1\",  'flavor': 'm1.medium', 'image': 'CC-Ubuntu20.04', 'packages': [], 'bastion': False}, \n",
    " {'name': \"node-2\",  'flavor': 'm1.medium', 'image': 'CC-Ubuntu20.04', 'packages': [], 'bastion': False} \n",
    "]\n",
    "net_conf = [\n",
    " {\"name\": \"net0\", \"subnet\": \"192.168.1.0/24\", \"nodes\": [{\"name\": \"node-0\",   \"addr\": \"192.168.1.10\"}, {\"name\": \"node-1\", \"addr\": \"192.168.1.11\"}, {\"name\": \"node-2\", \"addr\": \"192.168.1.12\"}]},\n",
    "]\n",
    "route_conf = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure resources\n",
    "\n",
    "Now, we will prepare the VMs and network links that our experiment requires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will prepare a “public” network that we will use for SSH access to our VMs -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "public_net = os_conn.network.create_network(name=\"public_net_\" + username)\n",
    "public_net_id = public_net.get(\"id\")\n",
    "public_subnet = os_conn.network.create_subnet(\n",
    "    name=\"public_subnet_\" + username,\n",
    "    network_id=public_net.get(\"id\"),\n",
    "    ip_version='4',\n",
    "    cidr=\"192.168.10.0/24\",\n",
    "    gateway_ip=\"192.168.10.1\",\n",
    "    is_dhcp_enabled = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will prepare the “experiment” networks -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nets = []\n",
    "net_ids = []\n",
    "subnets = []\n",
    "for n in net_conf:\n",
    "    exp_net = os_conn.network.create_network(name=\"exp_\" + n['name']  + '_' + username)\n",
    "    exp_net_id = exp_net.get(\"id\")\n",
    "    os_conn.network.update_network(exp_net, is_port_security_enabled=False)\n",
    "    exp_subnet = os_conn.network.create_subnet(\n",
    "        name=\"exp_subnet_\" + n['name']  + '_' + username,\n",
    "        network_id=exp_net.get(\"id\"),\n",
    "        ip_version='4',\n",
    "        cidr=n['subnet'],\n",
    "        gateway_ip=None,\n",
    "        is_dhcp_enabled = True\n",
    "    )\n",
    "    nets.append(exp_net)\n",
    "    net_ids.append(exp_net_id)\n",
    "    subnets.append(exp_subnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the VMs -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "servers = []\n",
    "server_ids = []\n",
    "for i, n in enumerate(node_conf, start=10):\n",
    "    image_uuid = os_conn.image.find_image(n['image']).id\n",
    "    flavor_uuid = os_conn.compute.find_flavor(n['flavor']).id\n",
    "    # find out details of exp interface(s)\n",
    "    nics = [{'net-id': chi.network.get_network_id( \"exp_\" + net['name']  + '_' + username ), 'v4-fixed-ip': node['addr']} for net in net_conf for node in net['nodes'] if node['name']==n['name']]\n",
    "    # also include a public network interface\n",
    "    nics.insert(0, {\"net-id\": public_net_id, \"v4-fixed-ip\":\"192.168.10.\" + str(i)})\n",
    "    server = chi.server.create_server(\n",
    "        server_name=n['name'] + \"_\" + username,\n",
    "        image_id=image_uuid,\n",
    "        flavor_id=flavor_uuid,\n",
    "        nics=nics\n",
    "    )\n",
    "    servers.append(server)\n",
    "    server_ids.append(chi.server.get_server(n['name'] + \"_\" + username).id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wait for all servers to come up before we proceed -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for server_id in server_ids:\n",
    "    chi.server.wait_for_active(server_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will set up SSH access to the VMs.\n",
    "\n",
    "First, we will make sure the “public” network is connected to the Internet. Then, we will configure it to permit SSH access on port 22 for each port connected to this network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'network_id': '95a4e9e7-6023-4ecd-84e6-046a452973b5',\n",
       " 'tenant_id': '13a1ac1ce275484caedc3394339486a1',\n",
       " 'subnet_id': '2334f627-ae29-4e93-86d9-392daac4de5f',\n",
       " 'subnet_ids': ['2334f627-ae29-4e93-86d9-392daac4de5f'],\n",
       " 'port_id': 'bc804260-3633-4ee8-b69a-c1fb9ecc24c7',\n",
       " 'id': '26e5466d-ff14-46c8-ba3b-ab3f822b463a'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connect them to the Internet on the \"public\" network (e.g. for software installation)\n",
    "router = chi.network.create_router('inet_router_' + username, gw_network_name='public')\n",
    "chi.network.add_subnet_to_router(router.get(\"id\"), public_subnet.get(\"id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4c276415-f923-45c1-b468-05effad7dd59', '47e042a8-1212-4e8f-a35d-2e7b090d4bbe', '34a72289-0d10-4fd9-8e6d-11e275984202']\n"
     ]
    }
   ],
   "source": [
    "print(server_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SDKException",
     "evalue": "No port on server 4c276415-f923-45c1-b468-05effad7dd59 was found matching your NAT destination network public_net_vrj2006_nyu_edu.Please check your config",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSDKException\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_112/3400212625.py\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_conf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'bastion'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bastion'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massociate_floating_ip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mserver_ips\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.10/site-packages/chi/server.py\u001b[0m in \u001b[0;36massociate_floating_ip\u001b[0;34m(server_id, floating_ip_address)\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m     \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m     \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_ips_to_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_server_by_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mips\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloating_ip_address\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfloating_ip_address\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.10/site-packages/openstack/cloud/_network_common.py\u001b[0m in \u001b[0;36madd_ips_to_server\u001b[0;34m(self, server, auto_ip, ips, ip_pool, wait, timeout, reuse, fixed_address, nat_destination)\u001b[0m\n\u001b[1;32m   1400\u001b[0m             )\n\u001b[1;32m   1401\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mips\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m             server = self.add_ip_list(\n\u001b[0m\u001b[1;32m   1403\u001b[0m                 \u001b[0mserver\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m                 \u001b[0mips\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.10/site-packages/openstack/cloud/_network_common.py\u001b[0m in \u001b[0;36madd_ip_list\u001b[0;34m(self, server, ips, wait, timeout, fixed_address, nat_destination)\u001b[0m\n\u001b[1;32m   1284\u001b[0m                 \u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'floating_ip_address'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m             )\n\u001b[0;32m-> 1286\u001b[0;31m             server = self._attach_ip_to_server(\n\u001b[0m\u001b[1;32m   1287\u001b[0m                 \u001b[0mserver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m                 \u001b[0mfloating_ip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf_ip\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.10/site-packages/openstack/cloud/_network_common.py\u001b[0m in \u001b[0;36m_attach_ip_to_server\u001b[0;34m(self, server, floating_ip, fixed_address, wait, timeout, skip_attach, nat_destination)\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_attach\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m                     self._neutron_attach_ip_to_server(\n\u001b[0m\u001b[1;32m   1052\u001b[0m                         \u001b[0mserver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m                         \u001b[0mfloating_ip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloating_ip\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.10/site-packages/openstack/cloud/_network_common.py\u001b[0m in \u001b[0;36m_neutron_attach_ip_to_server\u001b[0;34m(self, server, floating_ip, fixed_address, nat_destination)\u001b[0m\n\u001b[1;32m   1090\u001b[0m     ):\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Find an available port\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m         (port, fixed_address) = self._nat_destination_port(\n\u001b[0m\u001b[1;32m   1093\u001b[0m             \u001b[0mserver\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m             \u001b[0mfixed_address\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfixed_address\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.10/site-packages/openstack/cloud/_network_common.py\u001b[0m in \u001b[0;36m_nat_destination_port\u001b[0;34m(self, server, fixed_address, nat_destination)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                         \u001b[0mmaybe_ports\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_port\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmaybe_ports\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                     raise exceptions.SDKException(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                         \u001b[0;34mf'No port on server {server[\"id\"]} was found matching '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                         \u001b[0;34mf'your NAT destination network {nat_network[\"name\"]}.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSDKException\u001b[0m: No port on server 4c276415-f923-45c1-b468-05effad7dd59 was found matching your NAT destination network public_net_vrj2006_nyu_edu.Please check your config"
     ]
    }
   ],
   "source": [
    "# prepare SSH access on the servers that serve in \"bastion\" role\n",
    "# WARNING: this relies on undocumented behavior of associate_floating_ip \n",
    "# that it associates the IP with the first port on the server\n",
    "server_ips = []\n",
    "for i, n in enumerate(node_conf):\n",
    "    if 'bastion' in n and n['bastion']:\n",
    "        ip = chi.server.associate_floating_ip(server_ids[i])\n",
    "        server_ips.append(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os_conn.get_security_group(\"Allow SSH\"):\n",
    "    os_conn.create_security_group(\"Allow SSH\", \"Enable SSH traffic on TCP port 22\")\n",
    "    os_conn.create_security_group_rule(\"Allow SSH\", port_range_min=22, port_range_max=22, protocol='tcp', remote_ip_prefix='0.0.0.0/0')\n",
    "\n",
    "security_group_id = os_conn.get_security_group(\"Allow SSH\").id\n",
    "for port in chi.network.list_ports():\n",
    "    if port['port_security_enabled'] and port['network_id']==public_net.get(\"id\"):\n",
    "        os_conn.network.update_port(port['id'], security_groups=[security_group_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for ip in server_ips:\n",
    "    chi.server.wait_for_tcp(ip, port=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell may raise an error if some of your nodes are still getting set up! If that happens, wait a few minutes and try again. (And then a few minutes more, and try again, if it still raises an error.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "primary_remote = chi.ssh.Remote(server_ips[0])\n",
    "physical_ips = [n['addr'] for n in net_conf[0]['nodes']]\n",
    "server_remotes = [chi.ssh.Remote(physical_ip, gateway=primary_remote) for physical_ip in physical_ips]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to configure our resources, including software package installation and network configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "for i, n in enumerate(node_conf):\n",
    "    remote = server_remotes[i]\n",
    "    # enable forwarding\n",
    "    remote.run(f\"sudo sysctl -w net.ipv4.ip_forward=1\") \n",
    "    remote.run(f\"sudo firewall-cmd --zone=trusted --add-source=192.168.0.0/16 --permanent\")\n",
    "    remote.run(f\"sudo firewall-cmd --zone=trusted --add-source=172.16.0.0/12 --permanent\")\n",
    "    remote.run(f\"sudo firewall-cmd --zone=trusted --add-source=10.0.0.0/8 --permanent\")\n",
    "    remote.run(f\"sudo firewall-cmd --zone=trusted --add-source=127.0.0.0/8 --permanent\")\n",
    "    # these are required for etcd\n",
    "    remote.run(f\"sudo firewall-cmd --zone=public --add-port=4001/tcp\")\n",
    "    remote.run(f\"sudo firewall-cmd --zone=public --add-port=2379-2380/tcp\")\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, n in enumerate(node_conf):\n",
    "    # install packages\n",
    "    if len(n['packages']):\n",
    "            remote = server_remotes[i]\n",
    "            remote.run(f\"sudo apt update; sudo apt -y install \" + \" \".join(n['packages'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prepare a \"hosts\" file that has names and addresses of every node\n",
    "hosts_txt = [ \"%s\\t%s\" % ( n['addr'], n['name'] ) for net in net_conf  for n in net['nodes'] if type(n) is dict and n['addr']]\n",
    "for remote in server_remotes:\n",
    "    for h in hosts_txt:\n",
    "        remote.run(\"echo %s | sudo tee -a /etc/hosts > /dev/null\" % h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we also need to enable incoming traffic on the HTTP port\n",
    "if not os_conn.get_security_group(\"Allow HTTP 32000\"):\n",
    "    os_conn.create_security_group(\"Allow HTTP 32000\", \"Enable HTTP traffic on TCP port 32000\")\n",
    "    os_conn.create_security_group_rule(\"Allow HTTP 32000\", port_range_min=32000, port_range_max=32000, protocol='tcp', remote_ip_prefix='0.0.0.0/0')\n",
    "\n",
    "# add existing security group\n",
    "security_group_id = os_conn.get_security_group(\"Allow HTTP 32000\").id\n",
    "for port in chi.network.list_ports(): \n",
    "    if port['port_security_enabled'] and port['network_id']==public_net.get(\"id\"):\n",
    "        pri_security_groups = port['security_groups']\n",
    "        pri_security_groups.append(security_group_id)\n",
    "        os_conn.network.update_port(port['id'], security_groups=pri_security_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw the network topology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells will draw the network topology, for your reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nodes = [ (n['name'], {'color': 'pink'}) for n in net_conf ] + [(n['name'], {'color': 'lightblue'}) for n in node_conf ]\n",
    "edges = [(net['name'], node['name'], \n",
    "          {'label': node['addr'] + '/' + net['subnet'].split(\"/\")[1] }) if node['addr'] else (net['name'], node['name']) for net in net_conf for node in net['nodes'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(len(nodes),len(nodes)))\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(edges)\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G, pos, node_shape='s',  \n",
    "        node_color=[n[1]['color'] for n in nodes], \n",
    "        node_size=[len(n[0])*400 for n in nodes],  \n",
    "        with_labels=True);\n",
    "nx.draw_networkx_edge_labels(G,pos,\n",
    "                             edge_labels=nx.get_edge_attributes(G,'label'),\n",
    "                             font_color='gray',  font_size=8, rotate=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Kubespray to prepare a Kubernetes cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that are resources are “up”, we will use Kubespray, a software utility for preparing and configuring a Kubernetes cluster, to set them up as a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remote = chi.ssh.Remote(server_ips[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# install Python libraries required for Kubespray\n",
    "remote.run(\"virtualenv -p python3 myenv\")\n",
    "remote.run(\"git clone --branch release-2.22 https://github.com/kubernetes-sigs/kubespray.git\")\n",
    "remote.run(\"source myenv/bin/activate; cd kubespray; pip3 install -r requirements.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# copy config files to correct locations\n",
    "remote.run(\"mv kubespray/inventory/sample kubespray/inventory/mycluster\")\n",
    "remote.run(\"git clone https://github.com/teaching-on-testbeds/k8s.git\")\n",
    "remote.run(\"cp k8s/config/k8s-cluster.yml kubespray/inventory/mycluster/group_vars/k8s_cluster/k8s-cluster.yml\")\n",
    "remote.run(\"cp k8s/config/inventory.py    kubespray/contrib/inventory_builder/inventory.py\")\n",
    "remote.run(\"cp k8s/config/addons.yml      kubespray/inventory/mycluster/group_vars/k8s_cluster/addons.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build inventory for this specific topology\n",
    "physical_ips = [n['addr'] for n in net_conf[0]['nodes']]\n",
    "physical_ips_str = \" \".join(physical_ips)\n",
    "remote.run(f\"source myenv/bin/activate; declare -a IPS=({physical_ips_str});\"+\"cd kubespray; CONFIG_FILE=inventory/mycluster/hosts.yaml python3 contrib/inventory_builder/inventory.py ${IPS[@]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make sure \"controller\" node can SSH into the others\n",
    "remote.run('ssh-keygen -t rsa -b 4096 -f ~/.ssh/id_rsa -q -N \"\"')\n",
    "public_key = remote.run('cat ~/.ssh/id_rsa.pub').tail(\"stdout\")[2:]\n",
    "\n",
    "for physical_ip in physical_ips:\n",
    "    remote_worker = chi.ssh.Remote(physical_ip, gateway=remote)\n",
    "    remote_worker.run(f'echo {public_key} >> ~/.ssh/authorized_keys') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will actually build the cluster. It will take a long time, and you may see many warnings in the output - that’s OK. The instructions below explain how to tell whether it was successful or not.\n",
    "\n",
    "The output will be very long, so it will be truncated by default. When you see\n",
    "\n",
    "    Output of this cell has been trimmed on the initial display.\n",
    "    Displaying the first 50 top outputs.\n",
    "    Click on this message to get the complete output.\n",
    "\n",
    "at the end, click in order to see the rest of the output.\n",
    "\n",
    "When the process is finished, you will see a “PLAY RECAP” in the output (near the end):\n",
    "\n",
    "    PLAY RECAP *********************************************************************\n",
    "    localhost                  : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   \n",
    "    node-0                     : ok=752  changed=149  unreachable=0    failed=0    skipped=1276 rescued=0    ignored=8   \n",
    "    node-1                     : ok=652  changed=136  unreachable=0    failed=0    skipped=1124 rescued=0    ignored=3   \n",
    "    node-2                     : ok=535  changed=112  unreachable=0    failed=0    skipped=797  rescued=0    ignored=2   \n",
    "\n",
    "Make sure that each node shows `failed=0`. If not, you should re-run the cell to re-try the failed parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build the cluster\n",
    "remote.run(\"source myenv/bin/activate; cd kubespray; ansible-playbook -i inventory/mycluster/hosts.yaml  --become --become-user=root cluster.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# allow kubectl access for non-root user\n",
    "remote.run(\"sudo cp -R /root/.kube /home/cc/.kube; sudo chown -R cc /home/cc/.kube; sudo chgrp -R cc /home/cc/.kube\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check installation\n",
    "remote.run(\"kubectl get nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Docker\n",
    "\n",
    "Now that we have a Kubernetes cluster, we have a framework in place for container orchestration. But we still need to set up Docker, for building, sharing, and running those containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add the user to the \"docker\" group on all hosts\n",
    "for physical_ip in physical_ips:\n",
    "    remote_worker = chi.ssh.Remote(physical_ip, gateway=remote)\n",
    "    remote_worker.run(\"sudo groupadd -f docker; sudo usermod -aG docker $USER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set up a private distribution registry on the \"controller\" node for distributing containers\n",
    "# note: need a brand-new SSH session in order to \"get\" new group membership\n",
    "remote = chi.ssh.Remote(server_ips[0])\n",
    "remote.run(\"docker run -d -p 5000:5000 --restart always --name registry registry:2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set up docker configuration on all the hosts\n",
    "for physical_ip in physical_ips:\n",
    "    remote_worker = chi.ssh.Remote(physical_ip, gateway=remote)\n",
    "    remote_worker.run(\"sudo wget https://raw.githubusercontent.com/teaching-on-testbeds/k8s/main/config/daemon.json -O /etc/docker/daemon.json\")\n",
    "    remote_worker.run(\"sudo service docker restart\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check configuration\n",
    "remote.run(\"docker run hello-world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get SSH login details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we should be able to log in to our “controller” node over SSH! Run the following cell, and observe the output - you will see an SSH command this node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssh cc@129.114.24.252\n"
     ]
    }
   ],
   "source": [
    "print(\"ssh cc@\" + server_ips[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No resources found in default namespace.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Result cmd='kubectl get pods' exited=0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote.run(\"kubectl get pods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can open an SSH session as follows:\n",
    "\n",
    "-   In Jupyter, from the menu bar, use File \\> New \\> Terminal to open a new terminal.\n",
    "-   Copy the SSH command from the output above, and paste it into the terminal.\n",
    "\n",
    "Alternatively, you can use your local terminal to log on to each node, if you prefer. (On your local terminal, you may need to also specify your key path as part of the SSH command, using the `-i` argument followed by the path to your private key.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flyte Deployment v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace/flyte created\n",
      "persistentvolumeclaim/postgresql-pvc created\n",
      "persistentvolumeclaim/minio-pvc created\n",
      "service/postgres created\n",
      "deployment.apps/postgres created\n",
      "deployment.apps/minio created\n",
      "service/minio created\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Result cmd='kubectl apply -f onprem-flyte-dependencies.yaml' exited=0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading the needed dependencies for flyte into the master node\n",
    "remote.run(\"curl -sl https://raw.githubusercontent.com/davidmirror-ops/flyte-the-hard-way/main/docs/on-premises/single-node/manifests/onprem-flyte-dependencies.yaml > onprem-flyte-dependencies.yaml\")\n",
    "\n",
    "#running the dependencies yaml in master node \n",
    "remote.run(\"kubectl apply -f onprem-flyte-dependencies.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 11903  100 11903    0     0      0      0 --:--:-- --:--:-- --:--:--     0   0     0  65043      0 --:--:-- --:--:-- --:--:-- 65043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://get.helm.sh/helm-v3.16.4-linux-amd64.tar.gz\n",
      "Verifying checksum... Done.\n",
      "Preparing to install helm into /usr/local/bin\n",
      "helm installed into /usr/local/bin/helm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Result cmd='curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash' exited=0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#installing helm\n",
    "remote.run(\"curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace/flyte created\n",
      "\"rimusz\" already exists with the same configuration, skipping\n",
      "Hang tight while we grab the latest from your chart repositories...\n",
      "...Successfully got an update from the \"rimusz\" chart repository\n",
      "Update Complete. ⎈Happy Helming!⎈\n",
      "Release \"hostpath-provisioner\" does not exist. Installing it now.\n",
      "NAME: hostpath-provisioner\n",
      "LAST DEPLOYED: Mon Jan  6 05:55:27 2025\n",
      "NAMESPACE: flyte\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "TEST SUITE: None\n",
      "NOTES:\n",
      "The Hostpath Provisioner service has now been installed.\n",
      "\n",
      "A storage class named 'hostpath' has now been created\n",
      "and is available to provision dynamic volumes.\n",
      "\n",
      "You can use this storageclass by creating a `PersistentVolumeClaim` with the\n",
      "correct storageClassName attribute. For example:\n",
      "\n",
      "    ---\n",
      "    kind: PersistentVolumeClaim\n",
      "    apiVersion: v1\n",
      "    metadata:\n",
      "      name: test-dynamic-volume-claim\n",
      "    spec:\n",
      "      storageClassName: \"hostpath\"\n",
      "      accessModes:\n",
      "        - ReadWriteOnce\n",
      "      resources:\n",
      "        requests:\n",
      "          storage: 100Mi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Result cmd='helm upgrade --install hostpath-provisioner --namespace flyte rimusz/hostpath-provisioner' exited=0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote.run(\"kubectl create namespace flyte\")\n",
    "remote.run(\"helm repo add rimusz https://charts.rimusz.net\")\n",
    "remote.run(\"helm repo update\")\n",
    "remote.run(\"helm upgrade --install hostpath-provisioner --namespace flyte rimusz/hostpath-provisioner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                        READY   STATUS    RESTARTS   AGE\n",
      "minio-6dfd8b7d76-46j5k      0/1     Pending   0          15s\n",
      "postgres-5cd768484f-sxn2v   0/1     Pending   0          15s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Result cmd='kubectl get pods -n flyte' exited=0>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking pod status ( Object store MinIO and PgSQL database containers must be created)\n",
    "remote.run(\"kubectl get pods -n flyte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:             postgres-5cd768484f-sxn2v\n",
      "Namespace:        flyte\n",
      "Priority:         0\n",
      "Service Account:  default\n",
      "Node:             <none>\n",
      "Labels:           app.kubernetes.io/name=postgres\n",
      "                  pod-template-hash=5cd768484f\n",
      "Annotations:      <none>\n",
      "Status:           Pending\n",
      "IP:               \n",
      "IPs:              <none>\n",
      "Controlled By:    ReplicaSet/postgres-5cd768484f\n",
      "Containers:\n",
      "  postgres:\n",
      "    Image:      ecr.flyte.org/ubuntu/postgres:13-21.04_beta\n",
      "    Port:       5432/TCP\n",
      "    Host Port:  0/TCP\n",
      "    Limits:\n",
      "      cpu:     1\n",
      "      memory:  512Mi\n",
      "    Requests:\n",
      "      cpu:     10m\n",
      "      memory:  128Mi\n",
      "    Environment:\n",
      "      POSTGRES_PASSWORD:  postgres\n",
      "      POSTGRES_USER:      flyte\n",
      "      POSTGRES_DB:        flyte\n",
      "    Mounts:\n",
      "      /var/lib/postgresql/data from postgres-storage (rw)\n",
      "      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-xpnzs (ro)\n",
      "Conditions:\n",
      "  Type           Status\n",
      "  PodScheduled   False \n",
      "Volumes:\n",
      "  postgres-storage:\n",
      "    Type:       PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace)\n",
      "    ClaimName:  postgresql-pvc\n",
      "    ReadOnly:   false\n",
      "  kube-api-access-xpnzs:\n",
      "    Type:                    Projected (a volume that contains injected data from multiple sources)\n",
      "    TokenExpirationSeconds:  3607\n",
      "    ConfigMapName:           kube-root-ca.crt\n",
      "    ConfigMapOptional:       <nil>\n",
      "    DownwardAPI:             true\n",
      "QoS Class:                   Burstable\n",
      "Node-Selectors:              <none>\n",
      "Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n",
      "                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\n",
      "Events:\n",
      "  Type     Reason            Age   From               Message\n",
      "  ----     ------            ----  ----               -------\n",
      "  Warning  FailedScheduling  27s   default-scheduler  0/3 nodes are available: pod has unbound immediate PersistentVolumeClaims. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Result cmd='kubectl describe pod postgres-5cd768484f-sxn2v -n flyte' exited=0>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote.run(\"kubectl describe pod postgres-5cd768484f-sxn2v -n flyte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#add flyte through helm repo\n",
    "remote.run(\"helm repo add flyteorg https://flyteorg.github.io/flyte\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remote.run(\"mkdir -p ~/flyte-config\")\n",
    "\n",
    "#Creating local secret yaml for db password\n",
    "remote.run(\"\"\"cat <<EOF > ~/flyte-config/local-secret.yaml      \n",
    "apiVersion: v1\n",
    "kind: Secret\n",
    "metadata:\n",
    "  name: flyte-binary-inline-config-secret\n",
    "  namespace: flyte\n",
    "type: Opaque\n",
    "stringData:\n",
    "  202-database-secrets.yaml: |\n",
    "    database:\n",
    "      postgres:\n",
    "        password: \"postgres\" \n",
    "EOF\n",
    "\"\"\")\n",
    "\n",
    "#Applying local secret\n",
    "remote.run(\"kubectl create -f ~/flyte-config/postgres.yaml\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Installing flyte binary in K8s\n",
    "remote.run(\"curl -sL https://raw.githubusercontent.com/davidmirror-ops/flyte-the-hard-way/main/docs/on-premises/single-node/manifests/onprem-flyte-binary-values.yaml > onprem-flyte-binary-values.yaml\")\n",
    "\n",
    "remote.run(\"helm install flyte-binary flyteorg/flyte-binary  --values onprem-flyte-binary-values.yaml -n flyte\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remote.run(\"kubectl get pods -n flyte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring to connect to installed Flyte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Installing and configuring flytectl\n",
    "remote.run(\"curl -sL https://ctl.flyte.org/install | sudo bash -s -- -b /usr/local/bin\")\n",
    "remote.run(\"flytectl config init\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to change content of config file\n",
    "config_content = \"\"\"admin:\n",
    "  endpoint: localhost:8089\n",
    "  authType: Pkce\n",
    "  insecure: true\n",
    "logger:\n",
    "  show-source: true\n",
    "  level: 6\"\"\"\n",
    "\n",
    "remote.run(f\"\"\"cat << 'EOF' > $HOME/.flyte/config.yaml\n",
    "{config_content}\n",
    "EOF\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create DNS entry so that Flyte CLI connects to MinIO using its FDQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start three port forwarding sessions for Http/grpc/minio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and execute dummy workflow script to test \n",
    "remote.run(\"\"\"cat <<<EOF >hello_world.py\n",
    "from flytekit import task, workflow\n",
    "@task\n",
    "def say_hello() -> str:\n",
    "    return \"hello world\"\n",
    "@workflow\n",
    "def my_wf() -> str:\n",
    "    res = say_hello()\n",
    "    return res\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Running my_wf() {my_wf()}\")\n",
    "EOF\"\"\")\n",
    "\n",
    "remote.run(\"pyflyte run --remote hello_world.py my_wf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Flyte Deployment v1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remote.run(\"mkdir -p ~/flyte-config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remote.run(\"\"\"cat > ~/flyte-config/postgres.yaml << 'EOF'\n",
    "apiVersion: v1\n",
    "kind: PersistentVolumeClaim\n",
    "metadata:\n",
    "  name: postgres-pvc\n",
    "spec:\n",
    "  accessModes:\n",
    "    - ReadWriteOnce\n",
    "  resources:\n",
    "    requests:\n",
    "      storage: 10Gi\n",
    "---\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: postgres\n",
    "spec:\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: postgres\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: postgres\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: postgres\n",
    "        image: postgres:13\n",
    "        env:\n",
    "        - name: POSTGRES_DB\n",
    "          value: flyteadmin\n",
    "        - name: POSTGRES_USER\n",
    "          value: postgres\n",
    "        - name: POSTGRES_PASSWORD\n",
    "          value: postgrespassword\n",
    "        ports:\n",
    "        - containerPort: 5432\n",
    "        volumeMounts:\n",
    "        - name: postgres-storage\n",
    "          mountPath: /var/lib/postgresql/data\n",
    "      volumes:\n",
    "      - name: postgres-storage\n",
    "        persistentVolumeClaim:\n",
    "          claimName: postgres-pvc\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: postgres\n",
    "spec:\n",
    "  ports:\n",
    "  - port: 5432\n",
    "  selector:\n",
    "    app: postgres\n",
    "EOF\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remote.run(\"\"\"cat > ~/flyte-config/minio.yaml << 'EOF'\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: minio\n",
    "spec:\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: minio\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: minio\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: minio\n",
    "        image: minio/minio\n",
    "        args:\n",
    "        - server\n",
    "        - /data\n",
    "        - --console-address\n",
    "        - \":9001\"\n",
    "        env:\n",
    "        - name: MINIO_ROOT_USER\n",
    "          value: minio\n",
    "        - name: MINIO_ROOT_PASSWORD\n",
    "          value: miniostorage\n",
    "        ports:\n",
    "        - containerPort: 9000\n",
    "        - containerPort: 9001\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: minio\n",
    "spec:\n",
    "  ports:\n",
    "  - port: 9000\n",
    "    name: minio\n",
    "  - port: 9001\n",
    "    name: console\n",
    "  selector:\n",
    "    app: minio\n",
    "EOF\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Flyte values configuration\n",
    "remote.run(\"\"\"cat > ~/flyte-config/flyte-values.yaml << 'EOF'\n",
    "configuration:\n",
    "  database:\n",
    "    host: postgres\n",
    "    port: 5432\n",
    "    dbname: flyteadmin\n",
    "    username: postgres\n",
    "    password: postgrespassword\n",
    "  storage:\n",
    "    type: minio\n",
    "    container: my-bucket\n",
    "    connection:\n",
    "      access-key: minio\n",
    "      auth-type: accesskey\n",
    "      secret-key: miniostorage\n",
    "      secure: false\n",
    "      endpoint: \"http://minio.flyte:9000\"\n",
    "  auth:\n",
    "    enabled: false\n",
    "EOF\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remote.run(\"curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remote.run(\"helm repo add flyteorg https://flyteorg.github.io/flyte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remote.run(\"helm repo update\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remote.run(\"kubectl create namespace flyte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remote.run(\"kubectl apply -n flyte -f ~/flyte-config/postgres.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remote.run(\"kubectl apply -n flyte -f ~/flyte-config/minio.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remote.run(\"kubectl wait --for=condition=ready pod -l app=postgres -n flyte --timeout=300s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remote.run(\"kubectl wait --for=condition=ready pod -l app=minio -n flyte --timeout=300s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remote.run(\"helm install -n flyte flyte-backend flyteorg/flyte-binary --values ~/flyte-config/flyte-values.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remote.run(\"kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=flyte-binary -n flyte --timeout=300s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remote.run(\"kubectl -n flyte port-forward service/flyte-binary 8088:8088 8089:8089 &\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remote.run(\"\"\"mkdir -p ~/.flyte\n",
    "cat > ~/.flyte/config.yaml <<EOF\n",
    "admin:\n",
    "  endpoint: dns:///localhost:8088\n",
    "  insecure: true\n",
    "EOF\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remote.run(\"pip install flytekit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "Flyte is now installed! To access the UI:\n",
    "1. SSH into the controller node using: ssh cc@{server_ip}\n",
    "2. The Flyte UI will be available at: http://localhost:8088/console\n",
    "3. For running workflows, use the flytectl configuration at ~/.flyte/config.yaml\n",
    "\"\"\".format(server_ip=server_ips[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
