{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reserve and configure resources on KVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you run this experiment, you will:\n",
    "\n",
    "-   define the specific configuration of resources you need.\n",
    "-   “instantiate” an experiment with your reserved resources.\n",
    "-   wait for your resources to be configured.\n",
    "-   log in to resources to carry out the experiment.\n",
    "\n",
    "This exercise will guide you through those steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openstack, chi, chi.ssh, chi.network, chi.server, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we configure the Chameleon Python client.\n",
    "\n",
    "For this experiment, we’re going to use the KVM@TACC site, which we indicate below.\n",
    "\n",
    "We also need to specify the name of the Chameleon “project” that this experiment is part of. The project name will have the format “CHI-XXXXXX”, where the last part is a 6-digit number, and you can find it on your [user dashboard](https://chameleoncloud.org/user/dashboard/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, replace the project ID with your own project ID, then run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi.use_site(\"KVM@TACC\")\n",
    "PROJECT_NAME = \"CHI-XXXXXX\"\n",
    "chi.set(\"project_name\", PROJECT_NAME)\n",
    "\n",
    "# configure openstacksdk for actions unsupported by python-chi\n",
    "os_conn = chi.clients.connection()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define configuration for this experiment (3 VMs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this specific experiment, we will need 1 virtual machines connected to a common network. Each of the virtual machines will be of the `m1.large` type, with 4 VCPUs, 8 GB memory, 40 GB disk space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = os.getenv('USER')\n",
    "\n",
    "node_conf = [\n",
    " {'name': \"node-0\",  'flavor': 'm1.large', 'image': 'CC-Ubuntu22.04', 'packages': [\"virtualenv\"], 'bastion': True}, \n",
    "]\n",
    "net_conf = [\n",
    " {\"name\": \"net0\", \"subnet\": \"192.168.1.0/24\", \"nodes\": [{\"name\": \"node-0\",   \"addr\": \"192.168.1.10\"}]},\n",
    "]\n",
    "route_conf = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure resources\n",
    "\n",
    "Now, we will prepare the VMs and network links that our experiment requires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will prepare a “public” network that we will use for SSH access to our VMs -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_net = os_conn.network.create_network(name=\"public_net_\" + username)\n",
    "public_net_id = public_net.get(\"id\")\n",
    "public_subnet = os_conn.network.create_subnet(\n",
    "    name=\"public_subnet_\" + username,\n",
    "    network_id=public_net.get(\"id\"),\n",
    "    ip_version='4',\n",
    "    cidr=\"192.168.10.0/24\",\n",
    "    gateway_ip=\"192.168.10.1\",\n",
    "    is_dhcp_enabled = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will prepare the “experiment” networks -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nets = []\n",
    "net_ids = []\n",
    "subnets = []\n",
    "for n in net_conf:\n",
    "    exp_net = os_conn.network.create_network(name=\"exp_\" + n['name']  + '_' + username)\n",
    "    exp_net_id = exp_net.get(\"id\")\n",
    "    os_conn.network.update_network(exp_net, is_port_security_enabled=False)\n",
    "    exp_subnet = os_conn.network.create_subnet(\n",
    "        name=\"exp_subnet_\" + n['name']  + '_' + username,\n",
    "        network_id=exp_net.get(\"id\"),\n",
    "        ip_version='4',\n",
    "        cidr=n['subnet'],\n",
    "        gateway_ip=None,\n",
    "        is_dhcp_enabled = True\n",
    "    )\n",
    "    nets.append(exp_net)\n",
    "    net_ids.append(exp_net_id)\n",
    "    subnets.append(exp_subnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the VMs -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "servers = []\n",
    "server_ids = []\n",
    "for i, n in enumerate(node_conf, start=10):\n",
    "    image_uuid = os_conn.image.find_image(n['image']).id\n",
    "    flavor_uuid = os_conn.compute.find_flavor(n['flavor']).id\n",
    "    # find out details of exp interface(s)\n",
    "    nics = [{'net-id': chi.network.get_network_id( \"exp_\" + net['name']  + '_' + username ), 'v4-fixed-ip': node['addr']} for net in net_conf for node in net['nodes'] if node['name']==n['name']]\n",
    "    # also include a public network interface\n",
    "    nics.insert(0, {\"net-id\": public_net_id, \"v4-fixed-ip\":\"192.168.10.\" + str(i)})\n",
    "    server = chi.server.create_server(\n",
    "        server_name=n['name'] + \"_\" + username,\n",
    "        image_id=image_uuid,\n",
    "        flavor_id=flavor_uuid,\n",
    "        nics=nics\n",
    "    )\n",
    "    servers.append(server)\n",
    "    server_ids.append(chi.server.get_server(n['name'] + \"_\" + username).id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wait for all servers to come up before we proceed -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for server_id in server_ids:\n",
    "    chi.server.wait_for_active(server_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will set up SSH access to the VMs.\n",
    "\n",
    "First, we will make sure the “public” network is connected to the Internet. Then, we will configure it to permit SSH access on port 22 for each port connected to this network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect them to the Internet on the \"public\" network (e.g. for software installation)\n",
    "router = chi.network.create_router('inet_router_' + username, gw_network_name='public')\n",
    "chi.network.add_subnet_to_router(router.get(\"id\"), public_subnet.get(\"id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare SSH access on the servers that serve in \"bastion\" role\n",
    "# WARNING: this relies on undocumented behavior of associate_floating_ip \n",
    "# that it associates the IP with the first port on the server\n",
    "server_ips = []\n",
    "for i, n in enumerate(node_conf):\n",
    "    if 'bastion' in n and n['bastion']:\n",
    "        ip = chi.server.associate_floating_ip(server_ids[i])\n",
    "        server_ips.append(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os_conn.get_security_group(\"Allow SSH\"):\n",
    "    os_conn.create_security_group(\"Allow SSH\", \"Enable SSH traffic on TCP port 22\")\n",
    "    os_conn.create_security_group_rule(\"Allow SSH\", port_range_min=22, port_range_max=22, protocol='tcp', remote_ip_prefix='0.0.0.0/0')\n",
    "\n",
    "security_group_id = os_conn.get_security_group(\"Allow SSH\").id\n",
    "for port in chi.network.list_ports(): \n",
    "    if port['port_security_enabled'] and port['network_id']==public_net.get(\"id\"):\n",
    "        os_conn.network.update_port(port['id'], security_groups=[security_group_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ip in server_ips:\n",
    "    chi.server.wait_for_tcp(ip, port=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell may raise an error if some of your nodes are still getting set up! If that happens, wait a few minutes and try again. (And then a few minutes more, and try again, if it still raises an error.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_remote = chi.ssh.Remote(server_ips[0])\n",
    "physical_ips = [n['addr'] for n in net_conf[0]['nodes']]\n",
    "server_remotes = [chi.ssh.Remote(physical_ip, gateway=primary_remote) for physical_ip in physical_ips]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to configure our resources, including software package installation and network configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "for i, n in enumerate(node_conf):\n",
    "    remote = server_remotes[i]\n",
    "    # enable forwarding\n",
    "    remote.run(f\"sudo sysctl -w net.ipv4.ip_forward=1\") \n",
    "    remote.run(f\"sudo firewall-cmd --zone=trusted --add-source=192.168.0.0/16 --permanent\")\n",
    "    remote.run(f\"sudo firewall-cmd --zone=trusted --add-source=172.16.0.0/12 --permanent\")\n",
    "    remote.run(f\"sudo firewall-cmd --zone=trusted --add-source=10.0.0.0/8 --permanent\")\n",
    "    remote.run(f\"sudo firewall-cmd --zone=trusted --add-source=127.0.0.0/8 --permanent\")\n",
    "    # these are required for etcd\n",
    "    remote.run(f\"sudo firewall-cmd --zone=public --add-port=4001/tcp\")\n",
    "    remote.run(f\"sudo firewall-cmd --zone=public --add-port=2379-2380/tcp\")\n",
    "    # add flyte ports\n",
    "    remote.run(f\"sudo firewall-cmd --zone=public --add-port=8088/tcp --permanent\")\n",
    "    remote.run(f\"sudo firewall-cmd --zone=public --add-port=8089/tcp --permanent\")\n",
    "    remote.run(f\"sudo firewall-cmd --zone=public --add-port=9000/tcp\")\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, n in enumerate(node_conf):\n",
    "    # install packages\n",
    "    if len(n['packages']):\n",
    "            remote = server_remotes[i]\n",
    "            remote.run(f\"sudo apt update; sudo apt -y install \" + \" \".join(n['packages'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare a \"hosts\" file that has names and addresses of every node\n",
    "hosts_txt = [ \"%s\\t%s\" % ( n['addr'], n['name'] ) for net in net_conf  for n in net['nodes'] if type(n) is dict and n['addr']]\n",
    "for remote in server_remotes:\n",
    "    for h in hosts_txt:\n",
    "        remote.run(\"echo %s | sudo tee -a /etc/hosts > /dev/null\" % h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we also need to enable incoming traffic on the HTTP port\n",
    "if not os_conn.get_security_group(\"Allow HTTP 32000\"):\n",
    "    os_conn.create_security_group(\"Allow HTTP 32000\", \"Enable HTTP traffic on TCP port 32000\")\n",
    "    os_conn.create_security_group_rule(\"Allow HTTP 32000\", port_range_min=32000, port_range_max=32000, protocol='tcp', remote_ip_prefix='0.0.0.0/0')\n",
    "\n",
    "# add existing security group\n",
    "security_group_id = os_conn.get_security_group(\"Allow HTTP 32000\").id\n",
    "for port in chi.network.list_ports(): \n",
    "    if port['port_security_enabled'] and port['network_id']==public_net.get(\"id\"):\n",
    "        pri_security_groups = port['security_groups']\n",
    "        pri_security_groups.append(security_group_id)\n",
    "        os_conn.network.update_port(port['id'], security_groups=pri_security_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we also need to enable incoming traffic on the HTTP port\n",
    "if not os_conn.get_security_group(\"Allow HTTP 8088\"):\n",
    "    os_conn.create_security_group(\"Allow HTTP 8088\", \"Enable HTTP traffic on TCP port 8088\")\n",
    "    os_conn.create_security_group_rule(\"Allow HTTP 8088\", port_range_min=8088, port_range_max=8088, protocol='tcp', remote_ip_prefix='0.0.0.0/0')\n",
    "\n",
    "# add existing security group\n",
    "security_group_id = os_conn.get_security_group(\"Allow HTTP 8088\").id\n",
    "for port in chi.network.list_ports(): \n",
    "    if port['port_security_enabled'] and port['network_id']==public_net.get(\"id\"):\n",
    "        pri_security_groups = port['security_groups']\n",
    "        pri_security_groups.append(security_group_id)\n",
    "        os_conn.network.update_port(port['id'], security_groups=pri_security_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw the network topology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells will draw the network topology, for your reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [ (n['name'], {'color': 'pink'}) for n in net_conf ] + [(n['name'], {'color': 'lightblue'}) for n in node_conf ]\n",
    "edges = [(net['name'], node['name'], \n",
    "          {'label': node['addr'] + '/' + net['subnet'].split(\"/\")[1] }) if node['addr'] else (net['name'], node['name']) for net in net_conf for node in net['nodes'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(len(nodes),len(nodes)))\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(edges)\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G, pos, node_shape='s',  \n",
    "        node_color=[n[1]['color'] for n in nodes], \n",
    "        node_size=[len(n[0])*400 for n in nodes],  \n",
    "        with_labels=True);\n",
    "nx.draw_networkx_edge_labels(G,pos,\n",
    "                             edge_labels=nx.get_edge_attributes(G,'label'),\n",
    "                             font_color='gray',  font_size=8, rotate=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Kubespray to prepare a Kubernetes cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that are resources are “up”, we will use Kubespray, a software utility for preparing and configuring a Kubernetes cluster, to set them up as a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote = chi.ssh.Remote(server_ips[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install Python libraries required for Kubespray\n",
    "remote.run(\"virtualenv -p python3 myenv\")\n",
    "remote.run(\"git clone --branch release-2.22 https://github.com/kubernetes-sigs/kubespray.git\")\n",
    "remote.run(\"source myenv/bin/activate; cd kubespray; pip3 install -r requirements.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy config files to correct locations\n",
    "remote.run(\"mv kubespray/inventory/sample kubespray/inventory/mycluster\")\n",
    "remote.run(\"git clone https://github.com/teaching-on-testbeds/k8s.git\")\n",
    "remote.run(\"cp k8s/config/k8s-cluster.yml kubespray/inventory/mycluster/group_vars/k8s_cluster/k8s-cluster.yml\")\n",
    "remote.run(\"cp k8s/config/inventory.py    kubespray/contrib/inventory_builder/inventory.py\")\n",
    "remote.run(\"cp k8s/config/addons.yml      kubespray/inventory/mycluster/group_vars/k8s_cluster/addons.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build inventory for this specific topology\n",
    "physical_ips = [n['addr'] for n in net_conf[0]['nodes']]\n",
    "physical_ips_str = \" \".join(physical_ips)\n",
    "remote.run(f\"source myenv/bin/activate; declare -a IPS=({physical_ips_str});\"+\"cd kubespray; CONFIG_FILE=inventory/mycluster/hosts.yaml python3 contrib/inventory_builder/inventory.py ${IPS[@]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure \"controller\" node can SSH into the others\n",
    "remote.run('ssh-keygen -t rsa -b 4096 -f ~/.ssh/id_rsa -q -N \"\"')\n",
    "public_key = remote.run('cat ~/.ssh/id_rsa.pub').tail(\"stdout\")[2:]\n",
    "\n",
    "for physical_ip in physical_ips:\n",
    "    remote_worker = chi.ssh.Remote(physical_ip, gateway=remote)\n",
    "    remote_worker.run(f'echo {public_key} >> ~/.ssh/authorized_keys') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will actually build the cluster. It will take a long time, and you may see many warnings in the output - that’s OK. The instructions below explain how to tell whether it was successful or not.\n",
    "\n",
    "The output will be very long, so it will be truncated by default. When you see\n",
    "\n",
    "    Output of this cell has been trimmed on the initial display.\n",
    "    Displaying the first 50 top outputs.\n",
    "    Click on this message to get the complete output.\n",
    "\n",
    "at the end, click in order to see the rest of the output.\n",
    "\n",
    "When the process is finished, you will see a “PLAY RECAP” in the output (near the end):\n",
    "\n",
    "    PLAY RECAP *********************************************************************\n",
    "    localhost                  : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   \n",
    "    node-0                     : ok=752  changed=149  unreachable=0    failed=0    skipped=1276 rescued=0    ignored=8   \n",
    "    node-1                     : ok=652  changed=136  unreachable=0    failed=0    skipped=1124 rescued=0    ignored=3   \n",
    "    node-2                     : ok=535  changed=112  unreachable=0    failed=0    skipped=797  rescued=0    ignored=2   \n",
    "\n",
    "Make sure that each node shows `failed=0`. If not, you should re-run the cell to re-try the failed parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the cluster\n",
    "remote.run(\"source myenv/bin/activate; cd kubespray; ansible-playbook -i inventory/mycluster/hosts.yaml  --become --become-user=root cluster.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow kubectl access for non-root user\n",
    "remote.run(\"sudo cp -R /root/.kube /home/cc/.kube; sudo chown -R cc /home/cc/.kube; sudo chgrp -R cc /home/cc/.kube\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check installation\n",
    "remote.run(\"kubectl get nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Docker\n",
    "\n",
    "Now that we have a Kubernetes cluster, we have a framework in place for container orchestration. But we still need to set up Docker, for building, sharing, and running those containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the user to the \"docker\" group on all hosts\n",
    "for physical_ip in physical_ips:\n",
    "    remote_worker = chi.ssh.Remote(physical_ip, gateway=remote)\n",
    "    remote_worker.run(\"sudo groupadd -f docker; sudo usermod -aG docker $USER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a private distribution registry on the \"controller\" node for distributing containers\n",
    "# note: need a brand-new SSH session in order to \"get\" new group membership\n",
    "remote = chi.ssh.Remote(server_ips[0])\n",
    "remote.run(\"docker run -d -p 5000:5000 --restart always --name registry registry:2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up docker configuration on all the hosts\n",
    "for physical_ip in physical_ips:\n",
    "    remote_worker = chi.ssh.Remote(physical_ip, gateway=remote)\n",
    "    remote_worker.run(\"sudo wget https://raw.githubusercontent.com/teaching-on-testbeds/k8s/main/config/daemon.json -O /etc/docker/daemon.json\")\n",
    "    remote_worker.run(\"sudo service docker restart\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check configuration\n",
    "remote.run(\"docker run hello-world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get SSH login details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we should be able to log in to our “controller” node over SSH! Run the following cell, and observe the output - you will see an SSH command this node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ssh cc@\" + server_ips[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can open an SSH session as follows:\n",
    "\n",
    "-   In Jupyter, from the menu bar, use File \\> New \\> Terminal to open a new terminal.\n",
    "-   Copy the SSH command from the output above, and paste it into the terminal.\n",
    "\n",
    "Alternatively, you can use your local terminal to log on to each node, if you prefer. (On your local terminal, you may need to also specify your key path as part of the SSH command, using the `-i` argument followed by the path to your private key.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Flyte on Kubernetes\n",
    "\n",
    "Now that we have our Kubernetes cluster ready, we’ll deploy Flyte using the following steps: 1. Setup storage using hostpath-provisioner 2. Deploy Flyte dependencies (PostgreSQL and MinIO) 3. Create Kubernetes secrets 4. Deploy Flyte using Helm 5. Configure and test the deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cloning repo\n",
    "remote.run(\"git clone https://github.com/ShaktidharK1997/flyte-artifact.git\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Namespaces\n",
    "\n",
    "Namespaces in Kubernetes provide a mechanism to organize and isolate a set of resources under a common identifier. In our case, we will keep all the created resources for the flyte deployment under a common namespace *flyte*. This will help us keep track of all the infrastructure that we have created for the flyte deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote.run(\"kubectl get namespace\")\n",
    "remote.run(\"kubectl create namespace flyte\")\n",
    "remote.run(\"kubectl get namespace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Storage Architecture\n",
    "\n",
    "Storage Classes provide a way to define different types of storage in Kubernetes. We’ll use the hostpath-provisioner which: - Creates a basic storage class for development environments - Provisions storage from the host machine’s filesystem - Automates PV creation when PVCs request storage\n",
    "\n",
    "The storage system consists of three main components: - PersistentVolumeClaims (PVCs): Acts as a request for storage - PersistentVolumes (PVs): Represents the actual storage resource - StorageClass: Automates PV creation\n",
    "\n",
    "PVC Request → StorageClass → PV Creation → Storage Available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for storage class in our K8s setup\n",
    "remote.run(\"kubectl get storageclass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing helm\n",
    "remote.run(\"curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash\")\n",
    "#installing hostpath provisioner\n",
    "remote.run(\"helm repo add rimusz https://charts.rimusz.net\")\n",
    "remote.run(\"helm repo update\")\n",
    "remote.run(\"helm upgrade --install hostpath-provisioner --namespace flyte rimusz/hostpath-provisioner\")\n",
    "remote.run(\"kubectl get storageclass -n flyte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#running the dependencies yaml in master node \n",
    "remote.run(\"kubectl apply -f flyte-artifact/config/onprem-flyte-dependencies.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking pod and service status ( Object store MinIO and PgSQL database containers must be created)\n",
    "remote.run(\"kubectl get pods -n flyte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Helm\n",
    "\n",
    "-   Helm is like a package manager for Kubernetes, similar to how pip is for python\n",
    "-   It helps you install and manage applications in your Kubernetes Cluster\n",
    "-   Applications are packaged as”charts” that contains all the Kubernetes manifests and configurations needed\n",
    "\n",
    "### Helm Repositories\n",
    "\n",
    "-   It is a catalog of available charts\n",
    "-   It’s a locatio where packaged charts are stored and can be shared\n",
    "-   Just like how PyPI is a repository for Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add flyte through helm repo\n",
    "remote.run(\"helm repo add flyteorg https://flyteorg.github.io/flyte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point the dependencies required by Flyte are ready. You can now choose which form factor to deploy:\n",
    "\n",
    "Single binary: all Flyte components (flyteadmin,flytepropeller, flyteconsole, etc) packaged into a single Pod. This is useful for environments with limited resources and a need for quick setup.\n",
    "\n",
    "Core: all components as standalone Pods, and potentially different number of replicas. This is required for multi-K8s-cluster environments.\n",
    "\n",
    "Since we are having a single-node setup, we will install a single binary flyte deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kubernetes Secret\n",
    "\n",
    "A Kubernetes Secret is an object that helps store and manage sensitive information like passwords, OAuth tokens, or SSH keys.\n",
    "\n",
    "In our specific case, the secret is needed because: - It stores the PostgreSQL database password that Flyte needs to connect to its backend database\n",
    "\n",
    "-   Instead of putting the password directly in the Helm values file (onprem-flyte-binary-values.yaml), which would be less secure, we’re creating a separate secret\n",
    "\n",
    "-   The name flyte-binary-inline-config-secret is specifically looked for by the Flyte binary chart to inject these configuration values\n",
    "\n",
    "-   The file 202-database-secrets.yaml inside the secret contains the database configuration with the password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote.run(\"kubectl create -f flyte-artifact/config/local_secret.yaml\")\n",
    "remote.run(\"kubectl describe secret flyte-binary-inline-config-secret -n flyte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Flyte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote.run(\"helm install flyte-binary flyteorg/flyte-binary  --values flyte-artifact/config/onprem-flyte-binary-values.yaml -n flyte\")\n",
    "remote.run(\"kubectl get pods -n flyte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration setup to connect to Flyte\n",
    "\n",
    "### Flytectl command-line interface (CLI) tool for Flyte.\n",
    "\n",
    "It allows you to: 1. Manage and interact with Flyte deployments 2. Create and update workflows 3. Monitor executions 4. Manage cluster resources 5. Handle authentication and configuration\n",
    "\n",
    "`flytectl config init` : Initializes the basic Flytectl configuration and creates a default config file at `$HOME/.flyte/config.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing and configuring flytectl\n",
    "\n",
    "remote.run(\"curl -sL https://ctl.flyte.org/install | sudo bash -s -- -b /usr/local/bin\")\n",
    "remote.run(\"flytectl config init\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copying contents of config.yaml into the flyte config file\n",
    "remote.run(\"cp flyte-artifact/config/config.yaml $HOME/.flyte/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating DNS Service for minio yaml \n",
    "remote.run(\"\"\"echo \"127.0.0.1 minio.flyte.svc.cluster.local\" | sudo tee -a /etc/hosts\"\"\")\n",
    "remote.run(\"cat /etc/hosts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote.run(\"source myenv/bin/activate; pip install flytekit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start three port forwarding sessions for Http/grpc/minio\n",
    "remote.run(\"\"\"\n",
    "# Start port forwards in the background using &\n",
    "nohup kubectl -n flyte port-forward --address 0.0.0.0 service/minio 9000:9000 > /tmp/minio.log 2>&1 &\n",
    "nohup kubectl -n flyte port-forward --address 0.0.0.0 service/flyte-binary-grpc 8089:8089 > /tmp/grpc.log 2>&1 &\n",
    "nohup kubectl -n flyte port-forward --address 0.0.0.0 service/flyte-binary-http 8088:8088 > /tmp/http.log 2>&1 &\n",
    "\n",
    "# Store the process IDs so we can terminate them later if needed\n",
    "echo $! > /tmp/flyte-portforward.pid\n",
    "\n",
    "# Print the running port forwards\n",
    "echo \"Port forwards running:\"\n",
    "ps aux | grep \"port-forward\" | grep -v grep\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote.run(\"source myenv/bin/activate; pyflyte run --remote flyte-artifact/scripts/rm hello_world.py my_wf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting created resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote.run(\"\"\"\n",
    "# Kill all port-forward processes\n",
    "pkill -f \"port-forward\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote.run(\"helm uninstall flyte-binary -n flyte\")\n",
    "remote.run(\"kubectl delete -f flyte-artifact/config/local_secret.yaml\")\n",
    "remote.run(\"kubectl delete -f flyte-artifact/config/onprem-flyte-dependencies.yaml\")\n",
    "remote.run(\"kubectl delete namespace flyte\")"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 }
}
